# 答题卡

## 1 并行策略与张量 shape

### 1.1 Column Parallel（Linear1）

#### 1.1.1 全局权重切分

全局权重矩阵

$$
W_1 \in \mathbb{R}^{d\times 4d} = \mathbb{R}^{1024 \times 4096}
$$

按列切分给 $P=4$ 个设备，每个 rank 上的子权重为

$$
W_1^{(i)} \in \mathbb{R}^{d \times \tfrac{4d}{P}} = \mathbb{R}^{1024 \times 1024}
$$

#### 1.1.2 输入张量分布

输入张量

$$
X \in \mathbb{R}^{B \times S \times d} = \mathbb{R}^{8 \times 128 \times 1024}
$$

在 Column Parallel 中，每个 rank 都保留完整的 $X$。

#### 1.1.3 局部输出与拼接

每个 rank 计算局部输出

$$
Y_i = X W_1^{(i)} \in \mathbb{R}^{8 \times 128 \times 1024}
$$

前向结束后，通过 **All‑Gather** 沿最后一维将所有 $Y_i$ 拼接，得到完整的

$$
Y = \text{concat}(Y_1, \dots, Y_4) \in \mathbb{R}^{8 \times 128 \times 4096}
$$

### 1.2 Row Parallel（Linear2）

#### 1.2.1 全局权重切分

全局权重矩阵

$$
W_2 \in \mathbb{R}^{4d \times d} = \mathbb{R}^{4096 \times 1024}
$$

按行切分给 $P=4$ 个设备，每个 rank 上的子权重为

$$
W_2^{(i)} \in \mathbb{R}^{\tfrac{4d}{P} \times d} = \mathbb{R}^{1024 \times 1024}
$$

#### 1.2.2 输入张量分布

Column Parallel 得到的完整 $Y\in\mathbb{R}^{8\times128\times4096}$ 被按最后一维切分，每个 rank 的输入为

$$
Y_i \in \mathbb{R}^{8 \times 128 \times 1024}
$$

#### 1.2.3 局部输出与汇总

每个 rank 计算局部输出

$$
Z_i = Y_i \, W_2^{(i)} \in \mathbb{R}^{8 \times 128 \times 1024}
$$

前向结束后，通过 **All‑Reduce** （元素逐位相加）将所有 $Z_i$ 聚合，得到完整输出

$$
Z = \sum_{i=1}^4 Z_i \in \mathbb{R}^{8 \times 128 \times 1024}
$$

## 2 通信分析

### 2.1 Column Parallel（Linear1）

#### 2.1.1 前向传播通信（All‑Gather）

- 每个 rank 本地发送 $Y_i\in\mathbb{R}^{8\times128\times1024}$ 给其它 $P-1=3$ 个 rank
- 通信量：$8 \times 128 \times 1024 \times 3 \approx 3.15\times10^6 \text{ 浮点数} \ (\sim12.6\text{MB})$

#### 2.1.2 反向传播通信（All‑Reduce）

> - 由于输入 $X$ 在各 rank 上被复制，梯度 $\partial L/\partial X$ 需要汇总，须进行通信
> - 各 rank 先本地计算 $\partial X_i$，再通过 **All‑Reduce** 求和，得到全局 $\partial X$

### 2.2 Row Parallel（Linear2）

#### 2.2.1 前向传播通信（All‑Reduce）

- 每个 rank 本地计算 $Z_i\in\mathbb{R}^{8\times128\times1024}$，再通过 **All‑Reduce** 求和
- 通信量：$8 \times 128 \times 1024 \times 3 \approx 3.15\times10^6 \text{ 浮点数} \ (\sim12.6\text{MB})$

#### 2.2.2 反向传播通信（All‑Gather）

> - 由于权重按行切分，对上一层输出梯度 $\partial Y$ 的列进行切分，各 rank 需将本地 $\partial Y_i$ 拼接，须进行通信
> - 通过 **All‑Gather** 沿最后一维恢复完整的 $\partial Y$ tensor

# 3 如果两层都使用 Row Parallel，会产生哪些额外通信？两层都使用 Column Parallel 会带来什么问题？
> - **两层都使用 Row Parallel**：则第一层（Linear1）前向传播中输入 $X$ 也须按行切分，计算输出 $Y$ 后需要额外的 All-Reduce 将各 rank 的局部 $Y_i$ 求和得到完整 $Y$；反向传播时输入梯度 $\partial X$ 则需要 All-Gather 恢复。相较于首层使用 Column Parallel 的情况，多了一个全局求和通信开销。总体而言，每层都采用行并行将增加前向和反向的 All-Reduce 通信开销。
>
> - **两层都使用 Column Parallel**：则第一层输出 $Y$ 还是通过列拼接得到完整；第二层前向传播则需要对完整的 $Y$ 进行复制到各 rank，再计算局部 $Z_i$ 并 All-Gather 拼接完整 $Z$。也就是说，第二层作为列并行需要先对第一层输出进行全局收集，这增加了通信和内存负担（需要在层与层之间全量传输激活）。而在反向传播中，两层都列并行会令输入梯度计算涉及 All-Reduce（首层 $\partial X$）和 All-Reduce（$\partial Y$）的转换，进一步增加复杂性。简言之，连续的列并行需要在层间进行额外的全局聚合，通信开销显著增大。